## Задача 1

	- создайте свой репозиторий на https://hub.docker.com;
	- выберете любой образ, который содержит веб-сервер Nginx; 
	- создайте свой fork образа;
	- реализуйте функциональность: запуск веб-сервера в фоне с индекс-страницей, содержащей HTML-код ниже:
		<head>
		<html>
		Hey, Netology
		</head>
		<body>
		<h1>I’m DevOps Engineer!</h1>
		</body>
		</html>
	
	- Опубликуйте созданный форк в своем репозитории и предоставьте ответ в виде ссылки на https://hub.docker.com/username_repo.
		docker run -d -p 8080:80  310383nthvbyfk/mordvintsev:nginx_v1.1
		https://hub.docker.com/repository/docker/310383nthvbyfk/mordvintsev
		
## Задача 2
	
	- Посмотрите на сценарий ниже и ответьте на вопрос: "Подходит ли в этом сценарии использование Docker контейнеров или лучше подойдет виртуальная машина, физическая машина? Может быть возможны разные варианты?"
	 Детально опишите и обоснуйте свой выбор.
	
	- Сценарий:
	
		* Высоконагруженное монолитное java веб-приложение; 
			Полагаю что для данного уловия лучьше использовать физичекую или виртуальную машину, чем больше кода - тем больше требуется ресурсов.  
		* Nodejs веб-приложение;
			Подходит для использования Docker контейнеров, т.к. Node.js добавляет возможность взаимодействовать с устройствами ввода-вывода через свой API, прямой путь к микросервисам.
		* Мобильное приложение c версиями для Android и iOS;
			Сдесь напрашиваетя гибридный подход, VM  совместно с Docker, DB на виртуалке, а микросервис  аутентификации,  push-уведомления, рассылки, мониторинг перенести в Docker
		* Шина данных на базе Apache Kafka;
			Брокер сообщений Kafka — распределенная система. Его серверы объединяются в кластеры. Хранение и пересылка сообщений идет параллельно на разных серверах, а это дает большую надежность и отказоустойчивость. 
			Даже при выходе из строя нескольких машин, сообщения все еще будут пересылаться и обрабатываться. 
			Виртуальные машины.
			
		* Elasticsearch кластер для реализации логирования продуктивного веб-приложения - три ноды elasticsearch, два logstash и две ноды kibana;
			Elasticsearch (ES) – масштабируемая утилита ,ядро ELK-стека (Elastic Stack), в состав которого водит Logstash, Kibana, FileBeat 
			Использовать под каждую ноду отдельную VM. 
	
		* Мониторинг-стек на базе Prometheus и Grafana;
			Гибрид из физической машины с Prometheus , Grafana в Docker.
		
		* MongoDB, как основное хранилище данных для java-приложения;
			Физческая машина или VM, обеспечивает максимальную производительность, бекап и копирование всей ос в случае с VM
		
		* Gitlab сервер для реализации CI/CD процессов и приватный (закрытый) Docker Registry.
			VM + Docker, VM для DB и фалового хранилища, Docker для сервисов .

## Задача 3
	Запустите первый контейнер из образа centos c любым тэгом в фоновом режиме, подключив папку /data из текущей рабочей директории на хостовой машине в /data контейнера;
	Запустите второй контейнер из образа debian в фоновом режиме, подключив папку /data из текущей рабочей директории на хостовой машине в /data контейнера;
	Подключитесь к первому контейнеру с помощью docker exec и создайте текстовый файл любого содержания в /data;
	Добавьте еще один файл в папку /data на хостовой машине;
	Подключитесь во второй контейнер и отобразите листинг и содержание файлов в /data контейнера.
		docker run  -ti  -v date:/date centos:7 bash
			[root@78df3b99f522 /]# ls -l /date/
				total 0
				-rw-r--r-- 1 root root 0 Nov 29 16:38 test1
				-rw-r--r-- 1 root root 0 Nov 29 16:39 test2
		docker run  -ti  -v date:/date debian:latest bash
			root@09c4d8a355b6:/date# ls -l
				total 0
				-rw-r--r-- 1 root root 0 Nov 29 16:38 test1
				-rw-r--r-- 1 root root 0 Nov 29 16:39 test2
	
	
## Задача 4 (*)
	Воспроизвести практическую часть лекции самостоятельно.
	
	Соберите Docker образ с Ansible, загрузите на Docker Hub и пришлите ссылку вместе с остальными ответами к задачам.